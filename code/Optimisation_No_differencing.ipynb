{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import numpy as np\\nimport csv\\nimport os\\nfrom multistep_lstm_company import MultiStepLSTMCompany\\nfrom datetime import date\\nimport math\\n\\n\\ndef get_optimal_epochs_batch_neurons_params(symbol, start_train_date, end_train_start_test_date, end_test_date, n_lags, n_seqs,\\n                                            n_epochs, n_batches, n_neurons, indicators, model_types):\\n    # This is optimising parameters for n_epochs, n_batch, and n_neurons\\n    # param = {\"n_epochs\": n_epochs, \"n_batch\": n_batch, \"n_neurons\": n_neurons}\\n    csv_columns = [\"Company\", \"LSTM Type\", \"n_epoch\", \"n_neuros\", \"n_batch\",\\n                   \"n_lag\", \"n_seq\", \"Training Time\",\\n                   \"Indicator Number\", \"Indicators\", \"Trained Date\",\\n                   \"Start Train Date\", \"End Train/Start Test Date\", \"End Test Date\",\\n                   \"Model Name\"]\\n    for i in range(30):\\n        csv_columns.append(\"Trend_t+\" + str(i+1))\\n        csv_columns.append(\"APRE_t+\" + str(i+1))\\n        csv_columns.append(\"RMSE_t+\" + str(i+1))\\n\\n    if not os.path.isdir(\"./experiments\"):\\n        # create directory\\n        os.mkdir(\"experiments\")\\n        \\n\\n    filename = \"./experiments/optimisation.csv\"\\n    if not os.path.isfile(filename):\\n        # create new file\\n        with open(filename, \"w\", newline=\"\") as csvfile:\\n            writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\\n            writer.writeheader()\\n\\n    for n_e in n_epochs:\\n        for n_b in n_batches:\\n            for n_n in n_neurons:\\n                for n_l in n_lags:\\n                    for n_s in n_seqs:\\n                        for m_t in model_types:\\n                            print(\"In process of training\", symbol, \"model type:\", m_t, \"n_lag:\",\\n                                  n_l, \"n_seq:\", n_s, \"n_epoch:\", n_e, \"n_batch:\", n_b, \"n_neurons:\", n_n)\\n                            obj = MultiStepLSTMCompany(symbol, start_train_date, end_train_start_test_date,\\n                                                       end_test_date, n_lag=n_l, n_seq=n_s, n_epochs=n_e,\\n                                                       n_neurons=n_n, n_batch=n_b, tech_indicators=indicators,\\n                                                       model_type=m_t)\\n                            obj.train()\\n                            predictions = obj.predict()\\n                            trend_score = obj.score(metric=\"trend\", predictions=predictions)\\n                            lstm_score = obj.score(metric=\"rmse\", predictions=predictions)\\n                            apre_score = obj.score(metric=\"apre\", predictions=predictions)\\n\\n                            dic = {\"Company\": symbol,\\n                                   \"LSTM Type\": obj.model_type,\\n                                   \"n_epoch\": obj.n_epochs,\\n                                   \"n_neuros\": obj.n_neurons,\\n                                   \"n_batch\": obj.n_batch,\\n                                   \"n_lag\": obj.n_lag,\\n                                   \"n_seq\": obj.n_seq,\\n                                   \"Training Time\": obj.time_taken_to_train,\\n                                   \"Start Train Date\": obj.train_start_date_string,\\n                                   \"End Train/Start Test Date\": obj.train_end_test_start_date_string,\\n                                   \"End Test Date\": obj.test_end_date_string,\\n                                   \"Indicator Number\": len(obj.input_tech_indicators_list) + 1,\\n                                   \"Indicators\": \"Share Price,\" + \",\".join(obj.input_tech_indicators_list),\\n                                   \"Trained Date\": str(date.today()),\\n                                    \"Model Name\": obj.create_file_name()}\\n                            for i in range(n_s):\\n                                dic[\"Trend_t+\" + str(i+1)] = trend_score[i]\\n                                dic[\"APRE_t+\" + str(i+1)] = apre_score[i]\\n                                dic[\"RMSE_t+\" + str(i+1)] = lstm_score[i]\\n\\n                            append_dict_to_csv(filename, csv_columns, dic)\\n\\ndef append_dict_to_csv(csv_file_name, csv_columns, dic):\\n    with open(csv_file_name, \\'a\\', newline=\\'\\') as csvfile:\\n        writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\\n        writer.writerow(dic)\\n\\n\\nn_lags = [3, 5]\\nn_seqs = [1, 3]\\nn_epochs = np.logspace(math.log(100, 10), math.log(5000, 10), num=10).astype(int)\\nn_neurons = np.logspace(math.log(1, 10), math.log(52, 10), num=10).astype(int)\\nn_batches = [\"full_batch\"]#, \"half_batch\", \"online\"]\\n#http://firsttimeprogrammer.blogspot.com/2015/09/selecting-number-of-neurons-in-hidden.html?m=1\\n\\nindicators = \"all\"\\nmodel_types = [\"vanilla\", \"stacked\", \"stacked\", \"bi\", \"cnn\", \"conv\"] # [\"vanilla\", \"stacked\", \"stacked\", \"bi\", \"cnn\", \"conv\"] #\\nstart_train_date = \"01/01/2000\"\\nend_train_start_test_date = \"01/01/2018\"\\nend_test_date = \"01/01/2019\"\\npred = get_optimal_epochs_batch_neurons_params(\"AMZN\", start_train_date, end_train_start_test_date, end_test_date, n_lags, n_seqs, n_epochs, n_batches, n_neurons, indicators, model_types)'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import numpy as np\n",
    "import csv\n",
    "import os\n",
    "from multistep_lstm_company import MultiStepLSTMCompany\n",
    "from datetime import date\n",
    "import math\n",
    "\n",
    "\n",
    "def get_optimal_epochs_batch_neurons_params(symbol, start_train_date, end_train_start_test_date, end_test_date, n_lags, n_seqs,\n",
    "                                            n_epochs, n_batches, n_neurons, indicators, model_types):\n",
    "    # This is optimising parameters for n_epochs, n_batch, and n_neurons\n",
    "    # param = {\"n_epochs\": n_epochs, \"n_batch\": n_batch, \"n_neurons\": n_neurons}\n",
    "    csv_columns = [\"Company\", \"LSTM Type\", \"n_epoch\", \"n_neuros\", \"n_batch\",\n",
    "                   \"n_lag\", \"n_seq\", \"Training Time\",\n",
    "                   \"Indicator Number\", \"Indicators\", \"Trained Date\",\n",
    "                   \"Start Train Date\", \"End Train/Start Test Date\", \"End Test Date\",\n",
    "                   \"Model Name\"]\n",
    "    for i in range(30):\n",
    "        csv_columns.append(\"Trend_t+\" + str(i+1))\n",
    "        csv_columns.append(\"APRE_t+\" + str(i+1))\n",
    "        csv_columns.append(\"RMSE_t+\" + str(i+1))\n",
    "\n",
    "    if not os.path.isdir(\"./experiments\"):\n",
    "        # create directory\n",
    "        os.mkdir(\"experiments\")\n",
    "        \n",
    "\n",
    "    filename = \"./experiments/optimisation.csv\"\n",
    "    if not os.path.isfile(filename):\n",
    "        # create new file\n",
    "        with open(filename, \"w\", newline=\"\") as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\n",
    "            writer.writeheader()\n",
    "\n",
    "    for n_e in n_epochs:\n",
    "        for n_b in n_batches:\n",
    "            for n_n in n_neurons:\n",
    "                for n_l in n_lags:\n",
    "                    for n_s in n_seqs:\n",
    "                        for m_t in model_types:\n",
    "                            print(\"In process of training\", symbol, \"model type:\", m_t, \"n_lag:\",\n",
    "                                  n_l, \"n_seq:\", n_s, \"n_epoch:\", n_e, \"n_batch:\", n_b, \"n_neurons:\", n_n)\n",
    "                            obj = MultiStepLSTMCompany(symbol, start_train_date, end_train_start_test_date,\n",
    "                                                       end_test_date, n_lag=n_l, n_seq=n_s, n_epochs=n_e,\n",
    "                                                       n_neurons=n_n, n_batch=n_b, tech_indicators=indicators,\n",
    "                                                       model_type=m_t)\n",
    "                            obj.train()\n",
    "                            predictions = obj.predict()\n",
    "                            trend_score = obj.score(metric=\"trend\", predictions=predictions)\n",
    "                            lstm_score = obj.score(metric=\"rmse\", predictions=predictions)\n",
    "                            apre_score = obj.score(metric=\"apre\", predictions=predictions)\n",
    "\n",
    "                            dic = {\"Company\": symbol,\n",
    "                                   \"LSTM Type\": obj.model_type,\n",
    "                                   \"n_epoch\": obj.n_epochs,\n",
    "                                   \"n_neuros\": obj.n_neurons,\n",
    "                                   \"n_batch\": obj.n_batch,\n",
    "                                   \"n_lag\": obj.n_lag,\n",
    "                                   \"n_seq\": obj.n_seq,\n",
    "                                   \"Training Time\": obj.time_taken_to_train,\n",
    "                                   \"Start Train Date\": obj.train_start_date_string,\n",
    "                                   \"End Train/Start Test Date\": obj.train_end_test_start_date_string,\n",
    "                                   \"End Test Date\": obj.test_end_date_string,\n",
    "                                   \"Indicator Number\": len(obj.input_tech_indicators_list) + 1,\n",
    "                                   \"Indicators\": \"Share Price,\" + \",\".join(obj.input_tech_indicators_list),\n",
    "                                   \"Trained Date\": str(date.today()),\n",
    "                                    \"Model Name\": obj.create_file_name()}\n",
    "                            for i in range(n_s):\n",
    "                                dic[\"Trend_t+\" + str(i+1)] = trend_score[i]\n",
    "                                dic[\"APRE_t+\" + str(i+1)] = apre_score[i]\n",
    "                                dic[\"RMSE_t+\" + str(i+1)] = lstm_score[i]\n",
    "\n",
    "                            append_dict_to_csv(filename, csv_columns, dic)\n",
    "\n",
    "def append_dict_to_csv(csv_file_name, csv_columns, dic):\n",
    "    with open(csv_file_name, 'a', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\n",
    "        writer.writerow(dic)\n",
    "\n",
    "\n",
    "n_lags = [3, 5]\n",
    "n_seqs = [1, 3]\n",
    "n_epochs = np.logspace(math.log(100, 10), math.log(5000, 10), num=10).astype(int)\n",
    "n_neurons = np.logspace(math.log(1, 10), math.log(52, 10), num=10).astype(int)\n",
    "n_batches = [\"full_batch\"]#, \"half_batch\", \"online\"]\n",
    "#http://firsttimeprogrammer.blogspot.com/2015/09/selecting-number-of-neurons-in-hidden.html?m=1\n",
    "\n",
    "indicators = \"all\"\n",
    "model_types = [\"vanilla\", \"stacked\", \"stacked\", \"bi\", \"cnn\", \"conv\"] # [\"vanilla\", \"stacked\", \"stacked\", \"bi\", \"cnn\", \"conv\"] #\n",
    "start_train_date = \"01/01/2000\"\n",
    "end_train_start_test_date = \"01/01/2018\"\n",
    "end_test_date = \"01/01/2019\"\n",
    "pred = get_optimal_epochs_batch_neurons_params(\"AMZN\", start_train_date, end_train_start_test_date, end_test_date, n_lags, n_seqs, n_epochs, n_batches, n_neurons, indicators, model_types)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-dc391e9399e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmultistep_lstm_company_no_differencing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMultiStepLSTMCompanyNoDifferencing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Github\\Hons-Project\\code\\multistep_lstm_company_no_differencing.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmultistep_lstm_company\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMultiStepLSTMCompany\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtime\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtime\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msleep\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Github\\Hons-Project\\code\\multistep_lstm_company.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Softwares\\Miniconda3\\envs\\Hons\\lib\\site-packages\\pandas\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig_init\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtseries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Softwares\\Miniconda3\\envs\\Hons\\lib\\site-packages\\pandas\\core\\api.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0misnull\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnotna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnotnull\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marrays\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGrouper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mset_eng_float_format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m from pandas.core.index import (Index, CategoricalIndex, Int64Index,\n",
      "\u001b[1;32mD:\\Softwares\\Miniconda3\\envs\\Hons\\lib\\site-packages\\pandas\\core\\groupby\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# flake8: noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m from pandas.core.groupby.groupby import (\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mGrouper\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGroupBy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeriesGroupBy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrameGroupBy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m )\n",
      "\u001b[1;32mD:\\Softwares\\Miniconda3\\envs\\Hons\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     44\u001b[0m from pandas.core.base import (PandasObject, SelectionMixin, GroupByError,\n\u001b[0;32m     45\u001b[0m                               DataError, SpecificationError)\n\u001b[1;32m---> 46\u001b[1;33m from pandas.core.index import (Index, MultiIndex,\n\u001b[0m\u001b[0;32m     47\u001b[0m                                CategoricalIndex, _ensure_index)\n\u001b[0;32m     48\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marrays\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mExtensionArray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Softwares\\Miniconda3\\envs\\Hons\\lib\\site-packages\\pandas\\core\\index.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# flake8: noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmulti\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_sparsify\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Softwares\\Miniconda3\\envs\\Hons\\lib\\site-packages\\pandas\\core\\indexes\\api.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategory\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCategoricalIndex\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmulti\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMultiIndex\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterval\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mIntervalIndex\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m from pandas.core.indexes.numeric import (NumericIndex, Float64Index,  # noqa\n\u001b[0;32m     13\u001b[0m                                     Int64Index, UInt64Index)\n",
      "\u001b[1;32mD:\\Softwares\\Miniconda3\\envs\\Hons\\lib\\site-packages\\pandas\\core\\indexes\\interval.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m     intervals_to_interval_bounds)\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetimes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdate_range\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimedeltas\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtimedelta_range\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmulti\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Softwares\\Miniconda3\\envs\\Hons\\lib\\site-packages\\pandas\\core\\indexes\\datetimes.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtseries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrequencies\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mto_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_period_alias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mResolution\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m from pandas.core.indexes.datetimelike import (\n\u001b[0m\u001b[0;32m     44\u001b[0m     DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin)\n\u001b[0;32m     45\u001b[0m from pandas.tseries.offsets import (\n",
      "\u001b[1;32mD:\\Softwares\\Miniconda3\\envs\\Hons\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mD:\\Softwares\\Miniconda3\\envs\\Hons\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mD:\\Softwares\\Miniconda3\\envs\\Hons\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "\u001b[1;32mD:\\Softwares\\Miniconda3\\envs\\Hons\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "\u001b[1;32mD:\\Softwares\\Miniconda3\\envs\\Hons\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "\u001b[1;32mD:\\Softwares\\Miniconda3\\envs\\Hons\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "from multistep_lstm_company_no_differencing import MultiStepLSTMCompanyNoDifferencing\n",
    "from datetime import date\n",
    "import math\n",
    "#\n",
    "indicators = \"all\"\n",
    "model_types = [\"vanilla\", \"stacked\", \"stacked\", \"bi\", \"cnn\", \"conv\"] # [\"vanilla\", \"stacked\", \"stacked\", \"bi\", \"cnn\", \"conv\"] #\n",
    "start_train_date = \"01/01/2000\"\n",
    "end_train_start_test_date = \"01/01/2018\"\n",
    "end_test_date = \"01/01/2019\"\n",
    "obj = MultiStepLSTMCompanyNoDifferencing(\"AMZN\", start_train_date, end_train_start_test_date,\n",
    "                                                       end_test_date, n_lag=5, n_seq=3, n_epochs=100,\n",
    "                                                       n_neurons=1, n_batch=\"full_batch\", tech_indicators=indicators,\n",
    "                                                       model_type=\"vanilla\")\n",
    "obj.train()\n",
    "predictions = obj.predict()\n",
    "trend_score = obj.score(metric=\"trend\", predictions=predictions)\n",
    "lstm_score = obj.score(metric=\"rmse\", predictions=predictions)\n",
    "apre_score = obj.score(metric=\"apre\", predictions=predictions)\n",
    "preds = np.array(predictions.tolist())[:-3 + 1]\n",
    "preds[:,1] - preds[:,2]\n",
    "test_values = obj.test_raw_series.values\n",
    "actual = list()\n",
    "for i in range(len(test_values) - obj.n_seq + 1):\n",
    "    next_days_values = test_values[i: i + obj.n_seq]\n",
    "    actual.append(next_days_values)\n",
    "actual = np.array(actual)\n",
    "import numpy as np\n",
    "#display(actual)\n",
    "#display(preds)\n",
    "#abs(actual[:, 1] - preds[:, 1])[-38] / \n",
    "#actual[:, 1][-38]\n",
    "display(obj.train_scaled.shape)\n",
    "display(obj.train_raw_series)\n",
    "display(obj.test_scaled.shape)\n",
    "display(obj.test_raw_series)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
