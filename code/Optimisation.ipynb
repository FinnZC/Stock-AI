{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In process of training AMZN model type: vanilla n_lag: 5 n_seq: 3 n_epoch: 100 n_batch: full_batch n_neurons: 1\n",
      "Preprocessing the data\n",
      "Retrieved price series and raw pd from disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Github\\Hons-Project\\code\\company.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  relevant_series_range.dropna(inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed data in  0.011609979470570882 mins\n",
      "Fitting the model\n",
      "train X size 4528  train X data dimension (4528, 5, 52) train y size 4528  train X data dimension (4528, 3)\n",
      "Training model with batch size 4528\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (4528, 1)                 216       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (4528, 3)                 6         \n",
      "=================================================================\n",
      "Total params: 222\n",
      "Trainable params: 222\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "New model with batch size 1 for prediction\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (1, 1)                    216       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (1, 3)                    6         \n",
      "=================================================================\n",
      "Total params: 222\n",
      "Trainable params: 222\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Reseting the lstm model\n",
      "Finished fitting the model, time taken to train: 0.4 mins\n",
      "Saving object and model\n",
      "Reseting the lstm model\n",
      "\n",
      "Calculating trend score for  1\n",
      "Correct counts:  150   Size of test set: 251\n",
      "\n",
      "Calculating trend score for  2\n",
      "Correct counts:  143   Size of test set: 251\n",
      "\n",
      "Calculating trend score for  3\n",
      "Correct counts:  144   Size of test set: 251\n",
      "t+1 RMSE: 41.394338\n",
      "t+2 RMSE: 76.124668\n",
      "t+3 RMSE: 106.543430\n",
      "t+1 APRE: 0.018345\n",
      "t+2 APRE: 0.038527\n",
      "t+3 APRE: 0.056108\n",
      "In process of training AMZN model type: stacked n_lag: 5 n_seq: 3 n_epoch: 100 n_batch: full_batch n_neurons: 1\n",
      "Preprocessing the data\n",
      "Retrieved price series and raw pd from disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Github\\Hons-Project\\code\\company.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  relevant_series_range.dropna(inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed data in  0.015641125043233235 mins\n",
      "Fitting the model\n",
      "train X size 4528  train X data dimension (4528, 5, 52) train y size 4528  train X data dimension (4528, 3)\n",
      "Training model with batch size 4528\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (4528, 5, 1)              216       \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (4528, 1)                 12        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (4528, 3)                 6         \n",
      "=================================================================\n",
      "Total params: 234\n",
      "Trainable params: 234\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "from multistep_lstm_company import MultiStepLSTMCompany\n",
    "from datetime import date\n",
    "import math\n",
    "\n",
    "\n",
    "def get_optimal_epochs_batch_neurons_params(symbol, start_train_date, end_train_start_test_date, end_test_date, n_lags, n_seqs,\n",
    "                                            n_epochs, n_batches, n_neurons, indicators, model_types):\n",
    "    # This is optimising parameters for n_epochs, n_batch, and n_neurons\n",
    "    # param = {\"n_epochs\": n_epochs, \"n_batch\": n_batch, \"n_neurons\": n_neurons}\n",
    "    csv_columns = [\"Company\", \"LSTM Type\", \"n_epoch\", \"n_neuros\", \"n_batch\",\n",
    "                   \"n_lag\", \"n_seq\", \"Training Time\",\n",
    "                   \"Indicator Number\", \"Indicators\", \"Trained Date\",\n",
    "                   \"Start Train Date\", \"End Train/Start Test Date\", \"End Test Date\",\n",
    "                   \"Model Name\"]\n",
    "    for i in range(30):\n",
    "        csv_columns.append(\"Trend_t+\" + str(i+1))\n",
    "        csv_columns.append(\"APRE_t+\" + str(i+1))\n",
    "        csv_columns.append(\"RMSE_t+\" + str(i+1))\n",
    "\n",
    "    if not os.path.isdir(\"./experiments\"):\n",
    "        # create directory\n",
    "        os.mkdir(\"experiments\")\n",
    "\n",
    "    filename = \"./experiments/optimisation.csv\"\n",
    "    if not os.path.isfile(filename):\n",
    "        # create new file\n",
    "        with open(filename, \"w\", newline=\"\") as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\n",
    "            writer.writeheader()\n",
    "\n",
    "    for n_e in n_epochs:\n",
    "        for n_b in n_batches:\n",
    "            for n_n in n_neurons:\n",
    "                for n_l in n_lags:\n",
    "                    for n_s in n_seqs:\n",
    "                        for m_t in model_types:\n",
    "                            print(\"In process of training\", symbol, \"model type:\", m_t, \"n_lag:\",\n",
    "                                  n_l, \"n_seq:\", n_s, \"n_epoch:\", n_e, \"n_batch:\", n_b, \"n_neurons:\", n_n)\n",
    "                            obj = MultiStepLSTMCompany(symbol, start_train_date, end_train_start_test_date,\n",
    "                                                       end_test_date, n_lag=n_l, n_seq=n_s, n_epochs=n_e,\n",
    "                                                       n_neurons=n_n, n_batch=n_b, tech_indicators=indicators,\n",
    "                                                       model_type=m_t)\n",
    "                            obj.train()\n",
    "                            predictions = obj.predict()\n",
    "                            trend_score = obj.score(metric=\"trend\", predictions=predictions)\n",
    "                            lstm_score = obj.score(metric=\"rmse\", predictions=predictions)\n",
    "                            apre_score = obj.score(metric=\"apre\", predictions=predictions)\n",
    "\n",
    "                            dic = {\"Company\": symbol,\n",
    "                                   \"LSTM Type\": obj.model_type,\n",
    "                                   \"n_epoch\": obj.n_epochs,\n",
    "                                   \"n_neuros\": obj.n_neurons,\n",
    "                                   \"n_batch\": obj.n_batch,\n",
    "                                   \"n_lag\": obj.n_lag,\n",
    "                                   \"n_seq\": obj.n_seq,\n",
    "                                   \"Training Time\": obj.time_taken_to_train,\n",
    "                                   \"Start Train Date\": obj.train_start_date_string,\n",
    "                                   \"End Train/Start Test Date\": obj.train_end_test_start_date_string,\n",
    "                                   \"End Test Date\": obj.test_end_date_string,\n",
    "                                   \"Indicator Number\": len(obj.input_tech_indicators_list) + 1,\n",
    "                                   \"Indicators\": \"Share Price,\" + \",\".join(obj.input_tech_indicators_list),\n",
    "                                   \"Trained Date\": str(date.today()),\n",
    "                                    \"Model Name\": obj.create_file_name()}\n",
    "                            for i in range(n_s):\n",
    "                                dic[\"Trend_t+\" + str(i+1)] = trend_score[i]\n",
    "                                dic[\"APRE_t+\" + str(i+1)] = apre_score[i]\n",
    "                                dic[\"RMSE_t+\" + str(i+1)] = lstm_score[i]\n",
    "\n",
    "                            append_dict_to_csv(filename, csv_columns, dic)\n",
    "\n",
    "def append_dict_to_csv(csv_file_name, csv_columns, dic):\n",
    "    with open(csv_file_name, 'a', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\n",
    "        writer.writerow(dic)\n",
    "\n",
    "\n",
    "n_lags = [5]\n",
    "n_seqs = [3]\n",
    "n_epochs = np.logspace(math.log(100, 10), math.log(5000, 10), num=10).astype(int)\n",
    "n_neurons = np.logspace(math.log(1, 10), math.log(52, 10), num=10).astype(int)\n",
    "n_batches = [\"full_batch\"]#, \"half_batch\", \"online\"]\n",
    "#http://firsttimeprogrammer.blogspot.com/2015/09/selecting-number-of-neurons-in-hidden.html?m=1\n",
    "\n",
    "indicators = \"all\"\n",
    "model_types = [\"vanilla\", \"stacked\", \"stacked\", \"bi\", \"cnn\", \"conv\"] # [\"vanilla\", \"stacked\", \"stacked\", \"bi\", \"cnn\", \"conv\"] #\n",
    "start_train_date = \"01/01/2000\"\n",
    "end_train_start_test_date = \"01/01/2018\"\n",
    "end_test_date = \"01/01/2019\"\n",
    "pred = get_optimal_epochs_batch_neurons_params(\"AMZN\", start_train_date, end_train_start_test_date, end_test_date, n_lags, n_seqs, n_epochs, n_batches, n_neurons, indicators, model_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import numpy as np\n",
    "import csv\n",
    "import os\n",
    "from multistep_lstm_company import MultiStepLSTMCompany\n",
    "from datetime import date\n",
    "import math\n",
    "#\n",
    "indicators = \"all\"\n",
    "model_types = [\"vanilla\", \"stacked\", \"stacked\", \"bi\", \"cnn\", \"conv\"] # [\"vanilla\", \"stacked\", \"stacked\", \"bi\", \"cnn\", \"conv\"] #\n",
    "start_train_date = \"01/01/2000\"\n",
    "end_train_start_test_date = \"01/01/2018\"\n",
    "end_test_date = \"01/01/2019\"\n",
    "obj = MultiStepLSTMCompany(\"AMZN\", start_train_date, end_train_start_test_date,\n",
    "                                                       end_test_date, n_lag=5, n_seq=3, n_epochs=100,\n",
    "                                                       n_neurons=1, n_batch=\"full_batch\", tech_indicators=indicators,\n",
    "                                                       model_type=\"vanilla\")\n",
    "obj.train()\n",
    "predictions = obj.predict()\n",
    "trend_score = obj.score(metric=\"trend\", predictions=predictions)\n",
    "lstm_score = obj.score(metric=\"rmse\", predictions=predictions)\n",
    "apre_score = obj.score(metric=\"apre\", predictions=predictions)\n",
    "preds = np.array(predictions.tolist())[:-3 + 1]\n",
    "preds[:,1] - preds[:,2]\n",
    "test_values = obj.test_raw_series.values\n",
    "actual = list()\n",
    "for i in range(len(test_values) - obj.n_seq + 1):\n",
    "    next_days_values = test_values[i: i + obj.n_seq]\n",
    "    actual.append(next_days_values)\n",
    "actual = np.array(actual)\n",
    "import numpy as np\n",
    "#display(actual)\n",
    "#display(preds)\n",
    "#abs(actual[:, 1] - preds[:, 1])[-38] / \n",
    "#actual[:, 1][-38]\n",
    "display(obj.train_scaled.shape)\n",
    "display(obj.train_raw_series)\n",
    "display(obj.test_scaled.shape)\n",
    "display(obj.test_raw_series)\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
